{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I / INF285 - Computación Científica  </h1>\n",
    "    <h2> Least Squares </h2>\n",
    "    <h2> <a href=\"#acknowledgements\"> [S]cientific [C]omputing [T]eam </a> </h2>\n",
    "    <h2> Version: 1.27</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [QR Factorization](#qr)\n",
    "* [Examples](#ex)\n",
    "* [Inconsistents Systems](#in)\n",
    "* [A Survey of Models](#sm)\n",
    "* [Acknowledgements](#acknowledgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as spla\n",
    "%matplotlib inline\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "from sklearn import datasets\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "M=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We have learned about square linear system of equations. \n",
    "However, How can we solve a non-square system? (More equations that unknowns!) Well, we need to find a least squares approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='qr' />\n",
    "\n",
    "# QR Factorization\n",
    "\n",
    "## Gram-Schmidt Orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm orthogonalize a set of input vectors, returning an **orthogonal set** that spans the same column space.\n",
    "We will only consider now that the input set of vectors are **linearly independent**.\n",
    "\n",
    "Let $A=[\\mathbf{a}_1\\, ...., \\mathbf{a}_n]$ a matrix with linearly independent column vectors $\\in\\mathbb{R}^m$ and $n \\le m$.\n",
    "\n",
    "We know the following for the orthogonal set:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{q}_i^*\\,\\mathbf{q}_i & = \\|\\mathbf{q}_i\\|_2^2= 1\\\\\n",
    "    \\mathbf{q}_i^*\\,\\mathbf{q}_j & = 0, \\, \\text{ for } i\\neq j\n",
    "\\end{align*}\n",
    "\n",
    "Then the Gram-Schmidt orthogonalization finds the $\\mathbf{q}_i$ and $r_{ij}$ from the following set of equations and considering the previous constraints:\n",
    "\\begin{align*}\n",
    "    \\mathbf{a}_1 &= r_{11}\\,\\mathbf{q}_1\\\\\n",
    "    r_{11} &= \\|\\mathbf{a}_1\\|_2\\\\\n",
    "    \\mathbf{q}_1 &= \\dfrac{\\mathbf{a}_1}{r_{11}}\\\\\n",
    "    \\mathbf{a}_2 &= r_{12}\\,\\mathbf{q}_1+r_{22}\\,\\mathbf{q}_2\\\\\n",
    "    r_{12} &= \\mathbf{q}_1^*\\,\\mathbf{a}_2\\\\\n",
    "    r_{22} &= \\|\\mathbf{a}_2-r_{12}\\,\\mathbf{q}_1\\|_2\\\\\n",
    "    \\mathbf{q}_2 &= \\dfrac{\\mathbf{a}_2-r_{12}\\,\\mathbf{q}_1}{r_{22}}\\\\\n",
    "    \\vdots &=  \\vdots\\\\\n",
    "    \\mathbf{a}_j &= \\sum_{i=1}^j r_{ij}\\,\\mathbf{q}_i\\\\\n",
    "    r_{ij} &= \\mathbf{q}_i^*\\,\\mathbf{a}_j, \\, \\text{ for } i<j\\\\\n",
    "    r_{jj} &= \\left\\|\\mathbf{a}_j-\\sum_{i=1}^{j-1} r_{ij}\\,\\mathbf{q}_i\\right\\|_2\\\\\n",
    "    \\mathbf{q}_j &= \\dfrac{\\mathbf{a}_j-\\sum_{i=1}^{j-1} r_{ij}\\,\\mathbf{q}_i}{r_jj}\\\\\n",
    "    \\vdots &=  \\vdots\\\\\n",
    "    \\mathbf{a}_n &= \\sum_{i=1}^n r_{in}\\,\\mathbf{q}_i\\\\\n",
    "    r_{in} &= \\mathbf{q}_i^*\\,\\mathbf{a}_n, \\, \\text{ for } i<n\\\\\n",
    "    r_{nn} &= \\left\\|\\mathbf{a}_n-\\sum_{i=1}^{n-1} r_{in}\\,\\mathbf{q}_i\\right\\|_2\\\\\n",
    "    \\mathbf{q}_n &= \\dfrac{\\mathbf{a}_n-\\sum_{i=1}^{n-1} r_{in}\\,\\mathbf{q}_i}{r_{nn}}\n",
    "\\end{align*}\n",
    "\n",
    "Thus, we obtain the QR decomposition as follows:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "                 \\mathbf{a}_{m\\times n} = Q_{m\\times n}R_{n\\times n}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "Where $Q$ is a matrix of vectors $\\mathbf{q}_{n}$, and $R$ is an upper-triangular matrix, with the coefficients $r_{ij}$:\n",
    "\n",
    "This is known as the **Reduced QR Factorization**. \n",
    "\n",
    "_**[IMPORTANT]** What is then a **full** QR decomposition?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "# A: A set of linearly independent columns\n",
    "# type_factorization: reduced or full\n",
    "# type_gram_schmidt: classic or modified\n",
    "def QR(A, type_factorization = 'reduced', type_gram_schmidt='classic'):\n",
    "    A.astype('float')\n",
    "    if type_factorization == 'reduced':\n",
    "        Q = np.zeros(A.shape)\n",
    "        R = np.zeros((A.shape[1],A.shape[1]))\n",
    "    elif type_factorization == 'full':\n",
    "        Q = np.zeros((A.shape[0],A.shape[0]))\n",
    "        R = np.zeros(A.shape)\n",
    "    for j in np.arange(A.shape[1]):\n",
    "        y = A[:,j]\n",
    "        for i in np.arange(j):\n",
    "            if type_gram_schmidt == 'classic':\n",
    "                R[i,j] = np.dot(Q[:,i],A[:,j])\n",
    "            elif type_gram_schmidt == 'modified':\n",
    "                R[i,j] = np.dot(Q[:,i],y)\n",
    "            y=y-R[i,j]*Q[:,i]\n",
    "        R[j,j] = np.linalg.norm(y)\n",
    "        Q[:,j] = y/np.linalg.norm(R[j,j])\n",
    "    # The following lines must be completed by you!\n",
    "    #if type_factorization == 'full':    \n",
    "        # (1) We need to add 0's to the R matrix so it is of the same shape as the matrix A, \n",
    "        # fortunately this was already done!\n",
    "        # (2) We need to add orthogonal vectors to Q so it is square,\n",
    "        # how do we do this?   \n",
    "    return Q,R          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -4]\n",
      " [ 2  3]\n",
      " [ 2  2]]\n",
      "[[ 1. -4.]\n",
      " [ 2.  3.]\n",
      " [ 2.  2.]]\n",
      "[[ 0.33333333 -0.93333333]\n",
      " [ 0.66666667  0.33333333]\n",
      " [ 0.66666667  0.13333333]]\n",
      "[[3. 2.]\n",
      " [0. 5.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,-4],[2,3],[2,2]])\n",
    "Qa, Ra = QR(A, type_factorization ='reduced', type_gram_schmidt='classic')\n",
    "print(A)\n",
    "print(np.dot(Qa,Ra))\n",
    "print(Qa)\n",
    "print(Ra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method let us resolve a system of equations. However, exists a **Full QR Factorization**, creating the next system:\n",
    "\n",
    "\\begin{equation}\n",
    "                 A_{m\\times n} = Q_{m\\times m}R_{m\\times n}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "Q is a square orthogonal matrix, adding $m-n$ columns and R grows adding $m-n$ zero rows.\n",
    "\n",
    "#### Theorem\n",
    "A square matrix $Q$ is orthogonal if $Q^*\\, = Q^{-1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ex' />\n",
    "\n",
    "## Examples\n",
    "\n",
    "### Normal vs Modified Gram-Schmidt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.e+00 1.e+00 1.e+00]\n",
      " [1.e-10 0.e+00 0.e+00]\n",
      " [0.e+00 1.e-10 0.e+00]\n",
      " [0.e+00 0.e+00 1.e-10]]\n",
      "What are the Q's?\n",
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e-10 -7.07106781e-01 -7.07106781e-01]\n",
      " [ 0.00000000e+00  7.07106781e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  7.07106781e-01]]\n",
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e-10 -7.07106781e-01 -4.08248290e-01]\n",
      " [ 0.00000000e+00  7.07106781e-01 -4.08248290e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  8.16496581e-01]]\n",
      "Are truly orthogonal the Q's?\n",
      "[[ 1.00000000e+00 -7.07106781e-11 -7.07106781e-11]\n",
      " [-7.07106781e-11  1.00000000e+00  5.00000000e-01]\n",
      " [-7.07106781e-11  5.00000000e-01  1.00000000e+00]]\n",
      "[[ 1.00000000e+00 -7.07106781e-11 -4.08248290e-11]\n",
      " [-7.07106781e-11  1.00000000e+00 -1.54826171e-16]\n",
      " [-4.08248290e-11 -1.54826171e-16  1.00000000e+00]]\n",
      "Showing Q1 and Q2\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.62324963e-27 -3.62324963e-27]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.62324963e-27 -1.77879510e-27]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.12420006e-27]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "d = 1e-10\n",
    "A = np.array([[1,1,1],[d,0,0],[0,d,0],[0,0,d]])\n",
    "print(A)\n",
    "\n",
    "Q1,R1 = QR(A, type_gram_schmidt = 'classic')\n",
    "Q2,R2 = QR(A, type_gram_schmidt = 'modified')\n",
    "\n",
    "# What are the Q's?\n",
    "print('What are the Q\\'s?')\n",
    "print(Q1)\n",
    "print(Q2)\n",
    "# Are truly orthogonal the Q's?\n",
    "print('Are truly orthogonal the Q\\'s?')\n",
    "print(np.dot(Q1.transpose(),Q1)) # Warning: We are just using the transpose since the matrices are real!\n",
    "print(np.dot(Q2.transpose(),Q2))\n",
    "# Do we recover A?\n",
    "print('Showing Q1 and Q2')\n",
    "print(np.dot(Q1,R1)-A)\n",
    "print(np.dot(Q2,R2)-A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='in' />\n",
    "\n",
    "## Overdetermined Linear Systems of Equations\n",
    "\n",
    "There is cases where the number of equations is greater than variables. Many times, those systems don't have an exact solution (inconsistent system). Then, in this case we needs an approximation closest to the data. Based in orthogonality, the shortest distance from a point to plane. The orthogonal distance represents the error which would be minimum.\n",
    "\n",
    "\\begin{equation} \n",
    "                 \\mathbf{b} - A\\,\\mathbf{x} = \\mathbf{r}\\\\\n",
    "                 \\mathbf{b} - A\\,\\mathbf{x} \\perp \\{A\\,\\mathbf{x}\\, |\\, \\mathbf{x} \\in \\mathbb{R}^m\\}\n",
    "\\end{equation}\n",
    "\n",
    "The idea is that $\\mathbf{r}$ would be closest to zero. We need to apply orthogonality to find the vector that satisfied this condition.\n",
    "\n",
    "\\begin{equation} \n",
    "                 (A\\,\\mathbf{x})^*\\,(\\mathbf{b}-A\\,\\overline{\\mathbf{x}})=0, \\hspace{1cm} \\text{for all } \\mathbf{x} \\in \\mathbb{R}^n\\\\\n",
    "                 \\mathbf{x}^*\\, A^*\\,(\\mathbf{b}-A\\,\\overline{\\mathbf{x}})=0, \\hspace{1cm} \\text{for all } \\mathbf{x} \\in \\mathbb{R}^n\\\\\n",
    "                 A^*\\,(\\mathbf{b}-A\\,\\overline{\\mathbf{x}})=\\mathbf{0} \\\\\n",
    "                 A^*\\,A\\,\\overline{\\mathbf{x}}= A^*\\,\\mathbf{b} \\\\\n",
    "\\end{equation}\n",
    "\n",
    "This last equation gives us a new square $n\\times n$ matrix, which let us resolve the equation system.\n",
    "This linear system of equations is known as the **Normal Equations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(A,b):\n",
    "    Q,R = QR(A,type_gram_schmidt='modified')\n",
    "    return spla.solve_triangular(R,np.dot(Q.T,b))\n",
    "\n",
    "def solve_model(M):\n",
    "    A=M['A']\n",
    "    b=M['b']\n",
    "    M['x_bar']=least_squares(A,b)\n",
    "    return M\n",
    "\n",
    "def create_model(data, type_model='linear'):\n",
    "    if type_model == 'linear': # f(x)=a0+a1*x\n",
    "        A = np.ones((data.shape[0],2))\n",
    "        A[:,1] = data[:,0]\n",
    "        b = data[:,1]\n",
    "    if type_model == 'parabollic': # f(x)=a0+a1*x+a_2*x^2\n",
    "        A = np.ones((data.shape[0],3))\n",
    "        A[:,1] = data[:,0]\n",
    "        A[:,2] = data[:,0]**2\n",
    "        b = data[:,1]\n",
    "    if type_model == 'exponential': #f(x)=a0 \\exp(a1*x) = \\exp(\\log(a0)+a1*x) -> log(f(x))=log(a0)+a1*x = A0+a1+x (it is linear now!)\n",
    "        A = np.ones((data.shape[0],2))\n",
    "        A[:,1] = data[:,0]\n",
    "        b = np.log(data[:,1])\n",
    "    M = {'A':A,\n",
    "         'b':b,\n",
    "         'type_model':type_model}\n",
    "    M=solve_model(M)\n",
    "    return M\n",
    "\n",
    "def evaluate_model(M,x):\n",
    "    x_bar=M['x_bar']\n",
    "    if M['type_model'] == 'linear':\n",
    "        return x_bar[0] + x_bar[1]*x\n",
    "    if M['type_model'] == 'parabollic':\n",
    "        return x_bar[0] + x_bar[1]*x + x_bar[2]*x**2\n",
    "    if M['type_model'] == 'exponential':\n",
    "        return np.exp(x_bar[0]+x_bar[1]*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(type_of_data='linear'):\n",
    "    n=40\n",
    "    np.random.seed(0)\n",
    "    x = np.linspace(0,10,n)\n",
    "    y = np.random.rand(n)\n",
    "    x = np.concatenate((x,x,y),axis=0)\n",
    "    n = 3*n\n",
    "    if type_of_data=='linear':\n",
    "        y = x+0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='parabollic':\n",
    "        y = 4*x**2+0.1*x*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='exponential':\n",
    "        y = np.exp(x+0.1*np.random.normal(0,1,n)+1.5)\n",
    "    elif type_of_data=='sinusoidal':\n",
    "        y = np.sin(2*np.pi*x/10)+0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='random':\n",
    "        y = 0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='boston house-prices':\n",
    "        x,y=datasets.load_boston(return_X_y=True)\n",
    "        x=x[:,5]\n",
    "    elif type_of_data=='diabetes':\n",
    "        x,y=datasets.load_diabetes(return_X_y=True)\n",
    "        x=x[:,2]\n",
    "    data = np.stack((x, y)).T\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16262b025f64efa8bdd3978cbbb8eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='type_of_data', index=6, options=('linear', 'parabollic', 'exponent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.looking_at_data(type_of_data='diabetes')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def looking_at_data(type_of_data='diabetes'):\n",
    "    data=generate_data(type_of_data)\n",
    "    Ml = create_model(data, type_model='linear')\n",
    "    Mp = create_model(data, type_model='parabollic')\n",
    "    Me = create_model(data, type_model='exponential')\n",
    "    xx=np.linspace(np.min(data[:,0])-0.1,np.max(data[:,0])+0.1,1000)\n",
    "    yyl=evaluate_model(Ml,xx)\n",
    "    yyp=evaluate_model(Mp,xx)\n",
    "    yye=evaluate_model(Me,xx)\n",
    "    \n",
    "    error_l=data[:,1]-evaluate_model(Ml,data[:,0])\n",
    "    error_p=data[:,1]-evaluate_model(Mp,data[:,0])\n",
    "    error_e=data[:,1]-evaluate_model(Me,data[:,0])\n",
    "    \n",
    "    plt.figure(figsize=(2*M,M))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(xx,yyl,'k-',linewidth=5,label='linear model')\n",
    "    plt.plot(xx,yyp,'y-',linewidth=20,label='parabollic model',alpha=0.4)\n",
    "    plt.plot(xx,yye,'g-',linewidth=5,label='exponential model')\n",
    "    plt.plot(data[:,0],data[:,1],'.b',markersize=20,label='original data',alpha=0.3)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.ylabel(r'$y$')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.ylim(0,10)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('What does this histogram tell us?')\n",
    "    three_errors=np.vstack((error_l, error_p, error_e)).T\n",
    "    plt.hist(three_errors, bins=20,\n",
    "             label=['linear','parabollic','exponential'],\n",
    "             color=['k','y','g'], alpha=0.5)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "widgets.interact(looking_at_data,type_of_data=['linear','parabollic','exponential','sinusoidal','random','boston house-prices','diabetes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Numpy Least Squares\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html\n",
    "\n",
    "### Numpy QR Factorization\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.qr.html\n",
    "\n",
    "### Scikit Learn Datasets\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='acknowledgements' />\n",
    "\n",
    "# Acknowledgements\n",
    "* _Material created by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) _and assistans: Laura Bermeo, Alvaro Salinas, Axel Símonsen and Martín Villanueva. DI UTFSM. April 2016._\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. June 2017.\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. July 2019.\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. August 2019.\n",
    "* _Update July 2020 - v1.27 - C.Torres_ : Fixing formatting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "state": {
    "7fd91d6f0d2545e7af10aae93cfe07e9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
